{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae55b97-8149-4571-91bb-ee4b15cd3d69",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4f1e5-c74e-46f7-8859-b7b0e16a5fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilters, MetadataFilter, FilterOperator, FilterCondition\n",
    ")\n",
    "from qdrant_client import QdrantClienta\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a19d16-c74b-4a93-a478-f3d96eef075c",
   "metadata": {},
   "source": [
    "# Documents loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f76e53-4527-45bd-9e2a-0e880db8b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input_data = '../../data/tmp'\n",
    "reader = SimpleDirectoryReader(input_dir=path_input_data)\n",
    "documents = reader.load_data(show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49c56e-dd7d-4017-ae8a-ce616d283b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)\n",
    "documents[0].to_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4e98a-c726-4b2b-a5b5-fe82bae424a6",
   "metadata": {},
   "source": [
    "## Metadata selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdca2a-49e2-4a32-90e9-244d3b359d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in documents:\n",
    "\n",
    "    # metadata gets injected into the text that the embeddings model & llm model receive.\n",
    "    # that actual text comes from a template.\n",
    "    # redefine the template the doc will use to parse the file metadata + file content.\n",
    "    d.text_template = \"<metadata>\\n{metadata_str}\\n</metadata>\\n\\n<content>\\n{content}\\n</content>\"\n",
    "    \n",
    "    # excluded_embed_metadata_keys\n",
    "    if 'page_label' not in d.excluded_embed_metadata_keys:\n",
    "        d.excluded_embed_metadata_keys.append('page_label')\n",
    "    if 'file_path' not in d.excluded_embed_metadata_keys:\n",
    "        d.excluded_embed_metadata_keys.append('file_path')\n",
    "    if 'file_name' in d.excluded_embed_metadata_keys:\n",
    "        d.excluded_embed_metadata_keys.remove('file_name')\n",
    "        \n",
    "    # excluded_llm_metadata_keys\n",
    "    if 'page_label' not in d.excluded_llm_metadata_keys:\n",
    "        d.excluded_llm_metadata_keys.append('page_label')\n",
    "    if 'file_path' not in d.excluded_llm_metadata_keys:\n",
    "        d.excluded_llm_metadata_keys.append('file_path')\n",
    "    if 'file_name' in d.excluded_llm_metadata_keys:\n",
    "        d.excluded_llm_metadata_keys.remove('file_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47514b-1016-452e-a42a-345ab59cb688",
   "metadata": {},
   "source": [
    "## Metadata extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf505309-3132-4ba4-bc56-1fd63207dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_re = re.compile(\n",
    "    r\"^\\s*(?P<year>\\d{4})\\s+(?P<quarter>Q[1-4])\\s+(?P<company>.+?)\\s*$\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "for d in documents:\n",
    "    m = filename_re.match(d.metadata.get('file_name').strip('.pdf'))\n",
    "    d.metadata['year'] = m.group('year')\n",
    "    d.metadata['quarter'] = m.group('quarter')\n",
    "    d.metadata['company'] = m.group('company')\n",
    "\n",
    "    if 'file_name' not in d.excluded_embed_metadata_keys:\n",
    "        d.excluded_embed_metadata_keys.append('file_name')\n",
    "    if 'file_name' not in d.excluded_llm_metadata_keys:\n",
    "        d.excluded_llm_metadata_keys.append('file_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a8603-602a-4d77-bb50-61953950e6b3",
   "metadata": {},
   "source": [
    "## Visualise Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d22eb-f832-4790-8bde-c294dab5db70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the parsed doc after metadata extraction (for the case of the embeddings model)\n",
    "print(documents[0].get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198c7b1-319b-42fd-b03e-3d5e092f9df8",
   "metadata": {},
   "source": [
    "# Vector index creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154987fa-ae45-44a0-8458-c5948d498847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_document_in_db(client: QdrantClient, collection_name: str, file_name: str, key: str = 'file_name') -> bool:\n",
    "    \"\"\"Check if document is already in the vector db.\"\"\"\n",
    "    scroll_filter = Filter(\n",
    "        must=[FieldCondition(key=key, match=MatchValue(value=file_name))]\n",
    "    )\n",
    "    \n",
    "    _, point_id = client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        scroll_filter=scroll_filter,\n",
    "        limit= 1,\n",
    "        with_payload=False,\n",
    "        with_vectors=False,\n",
    "    )\n",
    "    \n",
    "    return point_id is not None\n",
    "\n",
    "\n",
    "def collection_exists(client: QdrantClient, name: str) -> bool:\n",
    "    \"\"\"Check if collection exists in the vector db.\"\"\"\n",
    "    try:\n",
    "        _ = client.get_collection(name)\n",
    "        return True\n",
    "    except UnexpectedResponse as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "# get qdrant client\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "qdrant_client = QdrantClient(url=qdrant_url)\n",
    "collection_name = 'data'\n",
    "\n",
    "if collection_exists(client=qdrant_client, name=collection_name):\n",
    "    for d in documents[:]:\n",
    "        file_name = d.metadata['file_name']\n",
    "        if is_document_in_db(client=qdrant_client, collection_name=collection_name, file_name=file_name):\n",
    "            _ = logging.error(f'File: {file_name} already in vector db. Skipping...')\n",
    "            _ = documents.remove(d)\n",
    "        else:\n",
    "            _ = logging.info(f'Keeping file: {file_name}')\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    enable_hybrid=True,  # enable hybrid search\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985c173-37f4-4f0b-a326-6a50401f2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate HuggingFace embedding model\n",
    "model_name = 'BAAI/bge-small-en-v1.5'\n",
    "embeddings_model = HuggingFaceEmbedding(\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "# instantiate transformation pipeline\n",
    "chunk_size = 100\n",
    "chunk_overlap = 0\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap),\n",
    "        # TitleExtractor(),\n",
    "        embeddings_model,\n",
    "    ]\n",
    ")\n",
    "# transform documents\n",
    "nodes = pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7fdb0-df7b-41c6-bd5b-e9d4463a85b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HierarchicalNodeParser.from_defaults(\n",
    "#     chunk_sizes=[2048, 512, 128],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5076875-0ba3-46d1-a6ee-8af7250d348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build index and insert nodes\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812a8ca-aea3-411f-872d-c2fe002f8cdc",
   "metadata": {},
   "source": [
    "## Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99debb-821a-462b-817c-b1b8d2d7cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is amazon ticker?'\n",
    "\n",
    "# get retriever (specify the embeddings model)\n",
    "top_k = 4\n",
    "retriever = index.as_retriever(\n",
    "    embed_model=embeddings_model,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.DEFAULT,  # semantic\n",
    "    similarity_top_k=top_k,\n",
    ")\n",
    "\n",
    "results = retriever.retrieve(query)\n",
    "\n",
    "for r in results:\n",
    "    print(\"#### score:\", r.score)\n",
    "    print(\"#### text:\", r.node.get_content())\n",
    "    print(\"#### meta:\", r.node.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ca30e-c886-4b8b-b7f9-2db952e90dcc",
   "metadata": {},
   "source": [
    "## Keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574446d8-2e41-4921-9dca-079525fc5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is amazon ticker?'\n",
    "\n",
    "# get retriever (specify the embeddings model)\n",
    "top_k = 4\n",
    "retriever = index.as_retriever(\n",
    "    embed_model=embeddings_model,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.SPARSE,  # keyword\n",
    "    similarity_top_k=top_k,\n",
    ")\n",
    "\n",
    "results = retriever.retrieve(query)\n",
    "\n",
    "for r in results:\n",
    "    print(\"#### score:\", r.score)\n",
    "    print(\"#### text:\", r.node.get_content())\n",
    "    print(\"#### meta:\", r.node.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebe526-cbd8-4c08-9e67-7e2a6951dd7b",
   "metadata": {},
   "source": [
    "## Metadata filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6b389-bbb0-4681-a937-0e4c24e1bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"company\", value=\"AMZN\", operator=FilterOperator.EQ),\n",
    "        MetadataFilter(key=\"year\", value='2022', operator=FilterOperator.EQ),\n",
    "    ],\n",
    "    condition=FilterCondition.AND,\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    embed_model=embeddings_model,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.DEFAULT,  # semantic\n",
    "    similarity_top_k=5,\n",
    "    filters=filters,  # metadata\n",
    ")\n",
    "\n",
    "results = retriever.retrieve(query)\n",
    "\n",
    "for r in results:\n",
    "    print(\"#### score:\", r.score)\n",
    "    print(\"#### text:\", r.node.get_content())\n",
    "    print(\"#### meta:\", r.node.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6831a5a-ba5e-470b-b187-8c50db01faad",
   "metadata": {},
   "source": [
    "## Semantic + keyword + metadata search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700a811-0461-4012-b35c-6cde91cb440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_final = 3\n",
    "top_k_each = 5\n",
    "alpha = .5\n",
    "retriever = index.as_retriever(\n",
    "    embed_model=embeddings_model,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.HYBRID,  # semantic\n",
    "    similarity_top_k=top_k_final,  # controls the final number of returned nodes (after fusion).\n",
    "    sparse_top_k=top_k_each,  # how many nodes will be retrieved from each dense and sparse query.\n",
    "    alpha=alpha,  # by default applies relative_score_fusion\n",
    "    filters=filters,  # metadata\n",
    ")\n",
    "\n",
    "results = retriever.retrieve(query)\n",
    "\n",
    "for r in results:\n",
    "    print(\"#### score:\", r.score)\n",
    "    print(\"#### text:\", r.node.get_content())\n",
    "    print(\"#### meta:\", r.node.metadata)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d2999-d5d9-4f97-921b-5b25d823b8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
