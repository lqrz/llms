{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3517f8-19eb-4ec2-bff3-95f76e783d81",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662d71e8-5d56-43c1-9594-b11fde028e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134ec2f-031c-4e6a-84b8-99c77183cfc5",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9581f804-19c6-4b68-91da-1b5f592b4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn TfidfVectorizer uses base e.\n",
    "BASE = 'e'  # or 10 (int) for log10\n",
    "\n",
    "def log(x, base:BASE):\n",
    "    return np.log10(x) if base == 10 else np.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eeff74-402b-4fa7-aaac-46b27e6324e5",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2fbf370-5413-41a9-8a71-bdf52ed474a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'is', 'love', 'nurse', 'sorrow', 'sweet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'how': 0, 'is': 1, 'love': 2, 'nurse': 3, 'sorrow': 4, 'sweet': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# documents = [\n",
    "#     \"cat sat on mat\",\n",
    "#     \"cat cat sat sat sat on mat\",\n",
    "#     \"dog sat on log\",\n",
    "#     \"cat and dog are friends\",\n",
    "#     \"mat mat mat mat cat\",\n",
    "# ]\n",
    "# query = \"cat sat mat\"\n",
    "\n",
    "documents = [\n",
    "    \"sweet sweet nurse love\",\n",
    "    \"sweet sorrow\",\n",
    "    \"how sweet is love\",\n",
    "    \"nurse\"\n",
    "]\n",
    "query = \"sweet love\"\n",
    "\n",
    "\n",
    "vocabulary = sorted(set(chain(*map(lambda x: x.split(' '), documents))))\n",
    "w2ix = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "vocabulary\n",
    "w2ix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59a322c-6e58-4f4b-8a5f-4cc87812e55f",
   "metadata": {},
   "source": [
    "# Bag of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3853f2-c2dc-4d73-8487-90389b162111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 1, 0, 2],\n",
       "        [0, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, vocabulary=None, max_features=None,)\n",
    "documents_transformed = vectorizer.fit_transform(documents).todense()\n",
    "query_transformed = vectorizer.transform([query]).todense()\n",
    "\n",
    "documents_transformed\n",
    "query_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39d047-2882-4abf-b779-794709362fd8",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f5ad0-a2b4-4207-8710-b4fcefa4f8be",
   "metadata": {},
   "source": [
    "The idea is basically that documents that contain a lot of words from the prompt are more likely to be relevant.\n",
    "\n",
    "Discounting weight to words that appear in all documents.\n",
    "\n",
    "It does not require stopwords cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000cb40c-0986-4808-9b55-f01a523ff433",
   "metadata": {},
   "source": [
    "# Sklearn computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acafb47-7624-4489-b580-a566252cac83",
   "metadata": {},
   "source": [
    "## Vectorise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8606dc-14fc-48cd-9664-95db0308fc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorrow</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>0.487088</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3\n",
       "how     0.000000  0.000000  1.386294  0.000000\n",
       "is      0.000000  0.000000  1.386294  0.000000\n",
       "love    0.693147  0.000000  0.693147  0.000000\n",
       "nurse   0.693147  0.000000  0.000000  0.693147\n",
       "sorrow  0.000000  1.386294  0.000000  0.000000\n",
       "sweet   0.487088  0.287682  0.287682  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorrow</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "how     0.000000\n",
       "is      0.000000\n",
       "love    0.693147\n",
       "nurse   0.000000\n",
       "sorrow  0.000000\n",
       "sweet   0.287682"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    vocabulary=None,\n",
    "    max_features=None,\n",
    "    norm=None,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "# this will learn the vocabulary & the idf\n",
    "# the tf is computed online on each .transform call.\n",
    "_ = vectorizer.fit(documents)\n",
    "\n",
    "# it internally smooths with + 1\n",
    "# otherwise a term that appears in all docs would have\n",
    "# an idf == 0; same as if the term did not exist.\n",
    "vectorizer.idf_ = vectorizer.idf_ - 1\n",
    "\n",
    "# --- smooth_id param\n",
    "# if smooth_idf = True: idf(t) = log( (1 + n) / (1 + df(t)) ) + 1\n",
    "# if smooth_idf = False: idf(t) = log( n / df(t) ) + 1\n",
    "\n",
    "# --- sublinear_tf param\n",
    "# if sublinear_tf = True: tf = (1. + log(cnt)) if cnt > 0 else 0.\n",
    "# if sublinear_tf = False: use raw counts\n",
    "\n",
    "documents_transformed_sklearn = (\n",
    "    np.asarray(vectorizer.transform(documents).todense())\n",
    ")\n",
    "\n",
    "query_transformed_sklearn = (\n",
    "    np.asarray(vectorizer.transform([query]).todense())\n",
    "    .reshape(-1,) \n",
    ")\n",
    "\n",
    "# pprint\n",
    "pd.DataFrame(documents_transformed_sklearn.T, index=vocabulary)  # [words, doc]\n",
    "pd.DataFrame(query_transformed_sklearn.T, index=vocabulary)  # [words, doc (1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c35a2-b947-4729-b799-581e2c2a52be",
   "metadata": {},
   "source": [
    "## Compute similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb4060-7ba4-4471-887d-6d59290db6ae",
   "metadata": {},
   "source": [
    "After vectorizing, document query relevance is computed using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e70eba-bcc3-46e5-b087-106da1bbf7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.92361025, 0.        , 0.        ,\n",
       "       0.38333289])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_transformed_sklearn_unit = query_transformed_sklearn / np.linalg.norm(query_transformed_sklearn, ord=2)\n",
    "query_transformed_sklearn_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9444e91b-3d41-47c3-b95b-08ff4a30b3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.63323936, 0.63323936, 0.        ,\n",
       "        0.44498969],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.97913937,\n",
       "        0.20318978],\n",
       "       [0.66037695, 0.66037695, 0.33018848, 0.        , 0.        ,\n",
       "        0.1370406 ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_transformed_sklearn_unit = documents_transformed_sklearn / np.linalg.norm(documents_transformed_sklearn, ord=2, axis=1)[:, np.newaxis]\n",
    "documents_transformed_sklearn_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d6f5b9-6c20-455a-b984-180877838ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75544555, 0.07788932, 0.35749763, 0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_query_relevance_sklearn = documents_transformed_sklearn_unit @ query_transformed_sklearn_unit\n",
    "document_query_relevance_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce49e7-8506-4662-b851-aa2412584398",
   "metadata": {},
   "source": [
    "## Manual computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b008d9-027b-4491-8697-acea83a36ae5",
   "metadata": {},
   "source": [
    "### Document vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a08acbf-9e92-4bf0-97dd-d38738aeddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Counter({'sweet': 2, 'nurse': 1, 'love': 1}),\n",
       " 1: Counter({'sweet': 1, 'sorrow': 1}),\n",
       " 2: Counter({'how': 1, 'sweet': 1, 'is': 1, 'love': 1}),\n",
       " 3: Counter({'nurse': 1})}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aux structure of [doc][word]: tf\n",
    "doc_word_counts = dict([(ix, Counter(x.split(' '))) for ix, x in enumerate(documents)])\n",
    "doc_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d36500-954f-4999-8ca6-d138c153bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'is', 'love', 'nurse', 'sorrow', 'sweet']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorrow</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3\n",
       "how     0.0  0.0  1.0  0.0\n",
       "is      0.0  0.0  1.0  0.0\n",
       "love    1.0  0.0  1.0  0.0\n",
       "nurse   1.0  0.0  0.0  1.0\n",
       "sorrow  0.0  1.0  0.0  0.0\n",
       "sweet   2.0  1.0  1.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorrow</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3\n",
       "how     0.000000  0.0  1.0  0.0\n",
       "is      0.000000  0.0  1.0  0.0\n",
       "love    1.000000  0.0  1.0  0.0\n",
       "nurse   1.000000  0.0  0.0  1.0\n",
       "sorrow  0.000000  1.0  0.0  0.0\n",
       "sweet   1.693147  1.0  1.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_smooth_term_frequency(cnt: int, base: int = BASE) -> float:\n",
    "    \"\"\"This is equivalent to TfidfVectorizer(sublinear_tf=True).\"\"\"\n",
    "    return (1. + log(cnt, base)) if cnt > 0 else 0.\n",
    "\n",
    "tf_documents = np.array([[0.] * len(documents) for _ in range(len(vocabulary))])  # [words, documents]\n",
    "tf_documents_smoothed = np.array([[0.] * len(documents) for _ in range(len(vocabulary))])  # [words, documents]\n",
    "for ix_w, w in enumerate(vocabulary):\n",
    "    for ix_d, d in enumerate(documents):\n",
    "        tf_documents[ix_w][ix_d] = doc_word_counts[ix_d][w]\n",
    "        tf_documents_smoothed[ix_w][ix_d] = compute_smooth_term_frequency(cnt=doc_word_counts[ix_d][w])\n",
    "\n",
    "# pprint\n",
    "vocabulary\n",
    "pd.DataFrame(tf_documents, index=vocabulary)\n",
    "pd.DataFrame(tf_documents_smoothed, index=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add32464-b6b5-418c-b25d-e88ec48db0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorrow</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             IDF\n",
       "how     1.386294\n",
       "is      1.386294\n",
       "love    0.693147\n",
       "nurse   0.693147\n",
       "sorrow  1.386294\n",
       "sweet   0.287682"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_documents = len(documents)\n",
    "# will never have a count of 0; otherwise the word would not be in the vocabulary\n",
    "df = (tf_documents >= 1).astype(int).sum(axis=1)\n",
    "idf = log(n_documents / df, base=BASE)[:, np.newaxis]  # [words x 1]\n",
    "\n",
    "pd.DataFrame(idf, index=vocabulary, columns=['IDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83275e7-76f5-4572-bacd-ed22a43e2323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorrow</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>0.487088</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3\n",
       "how     0.000000  0.000000  1.386294  0.000000\n",
       "is      0.000000  0.000000  1.386294  0.000000\n",
       "love    0.693147  0.000000  0.693147  0.000000\n",
       "nurse   0.693147  0.000000  0.000000  0.693147\n",
       "sorrow  0.000000  1.386294  0.000000  0.000000\n",
       "sweet   0.487088  0.287682  0.287682  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute document tf-idf vectorisation\n",
    "documents_transformed = tf_documents_smoothed * idf\n",
    "\n",
    "pd.DataFrame(documents_transformed, index=vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc495e-f549-424f-a107-847935d7653c",
   "metadata": {},
   "source": [
    "### Query vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b1641c-43f9-40f8-957d-f468465f3c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get query words\n",
    "query_words = query.split(' ')\n",
    "query_vocabulary = list(set(query_words))\n",
    "query_word_counts = Counter(query_words)\n",
    "\n",
    "# compute query tf (w/ the documents vocabulary)\n",
    "tf_query = [0] * len(vocabulary)\n",
    "tf_query = np.array([ compute_smooth_term_frequency(cnt=query_word_counts[w]) for ix_w, w in enumerate(vocabulary)])\n",
    "tf_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6e559a-274b-4024-badf-400f0f8c697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.69314718, 0.        , 0.        ,\n",
       "       0.28768207])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_transformed = tf_query * idf.reshape(-1,)\n",
    "query_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02192245-ded3-40ce-9b15-e1672a61eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.92361025, 0.        , 0.        ,\n",
       "       0.38333289])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_transformed_unit = query_transformed / np.linalg.norm(query_transformed, ord=2)\n",
    "query_transformed_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9a71f0-639b-4b06-ae03-5062b7a8445b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.66037695, 0.        ],\n",
       "       [0.        , 0.        , 0.66037695, 0.        ],\n",
       "       [0.63323936, 0.        , 0.33018848, 0.        ],\n",
       "       [0.63323936, 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.97913937, 0.        , 0.        ],\n",
       "       [0.44498969, 0.20318978, 0.1370406 , 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_transformed_unit = (documents_transformed / np.linalg.norm(documents_transformed, ord=2, axis=0))\n",
    "documents_transformed_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa17528-1cb1-4412-a1e2-d26740eddc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75544555, 0.07788932, 0.35749763, 0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_query_relevance = documents_transformed_unit.T @ query_transformed_unit\n",
    "document_query_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e975ef-62bd-4bde-aa4b-68c14f7e01ff",
   "metadata": {},
   "source": [
    "## Check manual == sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63dbc1e-c8e1-4a79-b42a-84b51b856e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75544555, 0.07788932, 0.35749763, 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.75544555, 0.07788932, 0.35749763, 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_query_relevance_sklearn\n",
    "document_query_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816fe80-111e-4a6d-9464-158641ba5aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
